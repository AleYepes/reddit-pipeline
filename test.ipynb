{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"<P id=\"P1\" author=\"Secure_Tax84\">\n",
    "  <T>A tool for finding and/or validating ideas ?</T>\n",
    "  Is there a tool to find validated ideas ? Or lets say i have an idea and i want to pay to get my idea validated quickly ?\n",
    "</P>\n",
    "  <C id=\"C1\" author=\"fork_that\" parent=\"P1\">\n",
    "    Many people consider paying customers the only way to validate an idea. So try and pre-sell people. But the reality is many things are pre-validated. If there are competitors in a market and are doing something pretty much the same but you&#x27;ve got a twist on the idea then it&#x27;s pre-validated.\n",
    "  </C>\n",
    "    <C id=\"C1.1\" author=\"Secure_Tax84\" parent=\"C1\">\n",
    "      How can i validate that people want that twist ?\n",
    "    </C>\n",
    "      <C id=\"C1.1.1\" author=\"fork_that\" parent=\"C1.1\">\n",
    "        Build it, if they don&#x27;t want that twist just remove it.\n",
    "      </C>\n",
    "        <C id=\"C1.1.1.1\" author=\"Secure_Tax84\" parent=\"C1.1.1\">\n",
    "          So there is no tool\n",
    "        </C>\n",
    "          <C id=\"C1.1.1.1.1\" author=\"LouisDosBuzios\" parent=\"C1.1.1.1\">\n",
    "            What kind of tool are you expecting exactly? Maybe you should build a tool for that ?\n",
    "          </C>\n",
    "          <C id=\"C1.1.1.1.2\" author=\"sinsquare\" parent=\"C1.1.1.1\">\n",
    "            Is a landing page creator the tool?\n",
    "          </C>\n",
    "            <C id=\"C1.1.1.1.2.1\" author=\"Secure_Tax84\" parent=\"C1.1.1.1.2\">\n",
    "              No, the user have the landing page and he needs to validate the idea. So not a creator\n",
    "            </C>\n",
    "  <C id=\"C2\" author=\"[deleted]\" parent=\"P1\">\n",
    "    [removed]\n",
    "  </C>\n",
    "    <C id=\"C2.1\" author=\"Secure_Tax84\" parent=\"C2\">\n",
    "      So no one tool where i can input a landing page and output 15 prospects\n",
    "    </C>\n",
    "      <C id=\"C2.1.1\" author=\"zotov8\" parent=\"C2.1\">\n",
    "        Sounds like Google or Facebook ads lol\n",
    "      </C>\n",
    "  <C id=\"C3\" author=\"JoaquimLey\" parent=\"P1\">\n",
    "    Hey you find it let me know! Most indiehackers struggle with this and turn to other indiehackers for feedback but most I really just concerned about building and growing their own product so unless you already have a audience/network/reach it is really hard to get eyes on it without ads or building a prototype\n",
    "  </C>\n",
    "    <C id=\"C3.1\" author=\"Secure_Tax84\" parent=\"C3\">\n",
    "      Thanks, this is what i mean too. And i thought there is a tool out there that could do this. But unfortunately, there isn‚Äôt.\n",
    "    </C>\n",
    "      <C id=\"C3.1.1\" author=\"rajanchandi\" parent=\"C3.1\">\n",
    "        There are tools to build landing pages for sure. One can also use search volume checker to estimate if people really care about what you are building. Been into this for a decade. DM me if you want to discuss further.\n",
    "      </C>\n",
    "  <C id=\"C4\" author=\"VBGBeveryday\" parent=\"P1\">\n",
    "    Yep! Check out [gummysearch.com](https://gummysearch.com), it&#x27;s my community research tool which lets you quickly find conversations around pain points and solution requests in online communities. One of the common use-cases is finding &amp; validating ideas quickly, across any niche.\n",
    "\n",
    "Would welcome you to sign up and give it a try if it sounds interesting! There&#x27;s a free tier and paid ones for advanced search features, but if you DM me I can give you a free trial of the paid plans. Cheers!\n",
    "  </C>\n",
    "    <C id=\"C4.1\" author=\"Secure_Tax84\" parent=\"C4\">\n",
    "      Thanks a lot. This could be the tool that i am looking for. I will take a look\n",
    "    </C>\n",
    "  <C id=\"C5\" author=\"Due-Tip-4022\" parent=\"P1\">\n",
    "    This is something I have put thought into. I think there is opportunity here as a service to offer. Possibly a lot of opportunity if you can automate much of it.\n",
    "\n",
    "First, actual validation can only happen with involving the target market. Period. Those who disagree with that have a fundamental misunderstanding of the purpose of this step. And they are taking a huge gamble. But anyway. \n",
    "\n",
    "Its a very manual process. So it is typically looked at as something only the founder can do.\n",
    "\n",
    "The problem with this, the founder likely has no idea what they are doing. They have to first learn the process, then figure out how to apply it to their idea, then figure out how to execute it correctly the first time they try. Which is not a good way to execute such a critical process.\n",
    "\n",
    "My thoughts are though the founder has to be heavily involved in the process, they don&#x27;t have to be the one who sets up the infrastructure. A surgeon doesn&#x27;t prep the patient or surgery room. Other people get everything ready for them to step in to do the important part.\n",
    "\n",
    "I think there should be a service that sets up the infrastructure for you and sets up all the method for you to then be a part of.\n",
    "\n",
    "What I picture is they create a simple website landing page for you that does all the simple validation step. Talking everything from buying the domain to the host to even setting up the payment gateway if one is warranted.  The point is turn key. To make it as quick and easy for someone to validate their idea as possible. Remove as much of the learning curve as possible. In which a we developer with WP, or even a global site you just get a page on, should be able to setup in an hour. Or less really if their own process was honed.\n",
    "\n",
    "Then the service would look at who the target market Is, and figure out which groups and forums they are at. Create an account, learn the rules of the group, then come up with the right strategy to penetrat each. Including well written copy to be used as either posts or comments on ther people&#x27;s posts. Including monitors that watch these places for keywords indicating opportunity to engage. Then the service writes the optimal copy for those opportunities and posts it on a platform that gets texted to the founder to approve or reject or take it from there before it&#x27;s actually posted. AI could probably do a lot of this, and/or low cost virtual assistant. The point is to drive that traffic to the website where the actual validation happens.\n",
    "\n",
    "Then the founder just takes over at any step.\n",
    "\n",
    "The point is to build the infrastructure capable of automating as much of the setting up of the validation foundation as possible for founders. So they don&#x27;t have to spend weeks or months reinventing the wheel.\n",
    "\n",
    " And to do that as efficiently as possible so that it can be a very inexpensive option for founders to validate multiple ideas.\n",
    "\n",
    "Ask yourself how much you would pay to have someone set that infrastructure up and start engaging for you? Then how many people in the startup world or the physical invention world would be customers, repeat customers?\n",
    "\n",
    "I think the opportunity is huge anyway.\n",
    "  </C>\n",
    "  <C id=\"C6\" author=\"rwalling\" parent=\"P1\">\n",
    "    Here&#x27;s a framework I use for evaluating ideas: [https://www.startupsfortherestofus.com/episodes/episode-628-the-5-p-m-idea-validation-framework](https://www.startupsfortherestofus.com/episodes/episode-628-the-5-p-m-idea-validation-framework#:~:text=The%205%20P.M.%20Idea%20Validation%20Framework%20is%20a%20helpful%20way,the%20size%20of%20the%20opportunity)\n",
    "\n",
    "And on our YouTube channel we offer up 7 new SaaS ideas every 6 or 8 weeks: https://microconf.com/youtube\n",
    "  </C>\n",
    "    <C id=\"C6.1\" author=\"Secure_Tax84\" parent=\"C6\">\n",
    "      Rob Walling commenting on my post ü•π\n",
    "Mama i made it ! \n",
    "I am a big fan of yours !! i watched all of your videos and i am big microconf fan ! \n",
    "Please do more conferences in europe !\n",
    "    </C>\n",
    "      <C id=\"C6.1.1\" author=\"rwalling\" parent=\"C6.1\">\n",
    "        LOL üôèüèª\n",
    "      </C>\n",
    "  <C id=\"C7\" author=\"RealVincentLee\" parent=\"P1\">\n",
    "    To validate ideas, you need tools like landing page builders, feedback tools and marketing tools. It&#x27;s possible to combine all those tools together, but it&#x27;s hard to automate everything...So you still have to do a lot of work manually.\n",
    "  </C>\n",
    "    <C id=\"C7.1\" author=\"officialchrisangell\" parent=\"C7\">\n",
    "      This^^ \n",
    "It‚Äôs still a manual process, and for good reason!\n",
    "You will get a lot of ‚Äúoh wow, this is amazing‚Äù from people blowing smoke yo your‚Ä¶\n",
    "\n",
    "Also, it‚Äôs a great way to test your assumptions with real users before even writing a single line of code.\n",
    "\n",
    "Oh, it also shoes investors you are willing to put in the work.\n",
    "\n",
    "We just closed a venture backed round and traction along with at least 10-12 letters of intent (LOIs) is crucial if you are looking to raise.\n",
    "\n",
    "If you are bootstrapping and want to do s ventures backed raise in the future, you CC will need a min of $10k a month to secure a seed in this market.\n",
    "    </C>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires transformers>=4.51.0\n",
    "# Requires sentence-transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-4B\")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving,\n",
    "# together with setting `padding_side` to \"left\":\n",
    "# model = SentenceTransformer(\n",
    "#     \"Qwen/Qwen3-Embedding-4B\",\n",
    "#     model_kwargs={\"attn_implementation\": \"flash_attention_2\", \"device_map\": \"auto\"},\n",
    "#     tokenizer_kwargs={\"padding_side\": \"left\"},\n",
    "# )\n",
    "\n",
    "# The queries and documents to embed\n",
    "queries = [\n",
    "    \"What is the capital of China?\",\n",
    "    \"Explain gravity\",\n",
    "]\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "]\n",
    "\n",
    "# Encode the queries and documents. Note that queries benefit from using a prompt\n",
    "# Here we use the prompt called \"query\" stored under `model.prompts`, but you can\n",
    "# also pass your own prompt via the `prompt` argument\n",
    "query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "# Compute the (cosine) similarity between the query and document embeddings\n",
    "similarity = model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)\n",
    "# tensor([[0.7534, 0.1147],\n",
    "#         [0.0320, 0.6258]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Verification\n",
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the 8-bit quantized model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"\\nModel successfully loaded onto GPU.\")\n",
    "print(\"Model's memory footprint:\")\n",
    "print(f\"{model.get_memory_footprint() / 1024**3:.2f} GB\")\n",
    "\n",
    "# conduct text completion\n",
    "print(\"\\nGenerating text...\")\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"\\n--- Model Output ---\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=16384\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"content:\", content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import scraper\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(submission.created_utc, tz=datetime.timezone.utc)\n",
    "(datetime.datetime.now(tz=datetime.timezone.utc) - datetime.datetime.fromtimestamp(submission.created_utc, tz=datetime.timezone.utc))#.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(submission.link_flair_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(subreddit.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import post\n",
    "import praw\n",
    "\n",
    "post_id = '1msvjkw'\n",
    "reddit = praw.Reddit(\"bot1\")\n",
    "submission = reddit.submission(id=post_id)\n",
    "\n",
    "print(f\"Title: {submission.title}\")\n",
    "print(f\"Author: {submission.author.name}\")\n",
    "print(f\"Score: {submission.score}\")\n",
    "print(f\"ID: {submission.id}\")\n",
    "print(f\"Subreddit: r/{submission.subreddit.display_name}\")\n",
    "print(f\"URL: {submission.url}\")\n",
    "print(f\"Number of Comments: {submission.num_comments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indented\n",
    "def linearize_tree_to_xml(submission, base_indentation=\"  \"):\n",
    "    output_lines = []\n",
    "    op_author = submission.author.name if submission.author else \"[deleted]\"\n",
    "\n",
    "    # Post block\n",
    "    output_lines.append(f'<C id=\"C1\" author=\"{op_author}\">')\n",
    "    # output_lines.append(f'<C id=\"C1\">')\n",
    "    output_lines.append(f'{base_indentation}<T>{submission.title.strip()}</T>')\n",
    "    body = submission.selftext.strip()\n",
    "    if body:\n",
    "        output_lines.append(f'{base_indentation}{body}')\n",
    "    output_lines.append(\"</C>\")\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    def process_comment(comment, id_prefix, parent_id=\"C1\", depth=1):\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            return\n",
    "\n",
    "        author_name = comment.author.name if comment.author else \"[deleted]\"\n",
    "        comment_id = f\"C{id_prefix}\"\n",
    "        indentation = base_indentation * depth\n",
    "\n",
    "        # Comment block\n",
    "        output_lines.append(f'{indentation}<C id=\"{comment_id}\" author=\"{author_name}\" parent=\"{parent_id}\">')\n",
    "        # output_lines.append(f'{indentation}<C id=\"{comment_id}\" parent=\"{parent_id}\">')\n",
    "        body_text = comment.body.strip()\n",
    "        if body_text:\n",
    "            output_lines.append(f'{indentation}{base_indentation}{body_text}')\n",
    "        output_lines.append(f\"{indentation}</C>\")\n",
    "\n",
    "        # Replies\n",
    "        for i, reply in enumerate(comment.replies, 1):\n",
    "            new_id_prefix = f\"{id_prefix}.{i}\"\n",
    "            process_comment(reply, new_id_prefix, parent_id=comment_id, depth=depth + 1)\n",
    "\n",
    "    for i, top_level_comment in enumerate(submission.comments, 2):\n",
    "        process_comment(top_level_comment, str(i))\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "llm_transcript = linearize_tree_to_xml(submission)\n",
    "# print(len(llm_transcript))\n",
    "print(llm_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indented + HTML parser\n",
    "import praw\n",
    "import html # Import the html library for escaping\n",
    "\n",
    "def linearize_tree_to_xml(submission, base_indentation=\"  \"):\n",
    "    output_lines = []\n",
    "    op_author = submission.author.name if submission.author else \"[deleted]\"\n",
    "\n",
    "    # Post block\n",
    "    output_lines.append(f'<P id=\"P1\" author=\"{op_author}\">')\n",
    "    output_lines.append(f'{base_indentation}<T>{html.escape(submission.title.strip())}</T>')\n",
    "    body = submission.selftext.strip()\n",
    "    if body:\n",
    "        output_lines.append(f'{base_indentation}{html.escape(body)}')\n",
    "    output_lines.append(\"</P>\")\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    def process_comment(comment, id_prefix, parent_id=\"P1\", depth=1):\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            return\n",
    "\n",
    "        author_name = comment.author.name if comment.author else \"[deleted]\"\n",
    "        comment_id = f\"C{id_prefix}\"\n",
    "        indentation = base_indentation * depth\n",
    "\n",
    "        # Comment block\n",
    "        output_lines.append(f'{indentation}<C id=\"{comment_id}\" author=\"{author_name}\" parent=\"{parent_id}\">')\n",
    "        body_text = comment.body.strip()\n",
    "        if body_text:\n",
    "            output_lines.append(f'{indentation}{base_indentation}{html.escape(body_text)}')\n",
    "        output_lines.append(f\"{indentation}</C>\")\n",
    "\n",
    "        # Replies\n",
    "        for i, reply in enumerate(comment.replies, 1):\n",
    "            new_id_prefix = f\"{id_prefix}.{i}\"\n",
    "            process_comment(reply, new_id_prefix, parent_id=comment_id, depth=depth + 1)\n",
    "\n",
    "    for i, top_level_comment in enumerate(submission.comments, 1):\n",
    "        process_comment(top_level_comment, str(i), parent_id=\"P1\", depth=1)\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "llm_transcript = linearize_tree_to_xml(submission)\n",
    "print(len(llm_transcript))\n",
    "print(llm_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not indented\n",
    "def linearize_tree_to_xml(submission):\n",
    "    output_lines = []\n",
    "    op_author = submission.author.name if submission.author else \"[deleted]\"\n",
    "\n",
    "    # Post block\n",
    "    output_lines.append(f'<P id=\"P1\" author=\"{op_author}\">')\n",
    "    output_lines.append(f'<T>{submission.title.strip()}</T>')\n",
    "    body = submission.selftext.strip()\n",
    "    if body:\n",
    "        output_lines.append(body)\n",
    "    output_lines.append(\"</P>\")\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    def process_comment(comment, id_prefix, parent_id=\"P1\"):\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            return\n",
    "\n",
    "        author_name = comment.author.name if comment.author else \"[deleted]\"\n",
    "        comment_id = f\"C{id_prefix}\"\n",
    "        body_text = comment.body.strip() if comment.body else \"[deleted]\"\n",
    "\n",
    "        # Comment block\n",
    "        output_lines.append(f'<C id=\"{comment_id}\" author=\"{author_name}\" parent=\"{parent_id}\">')\n",
    "        output_lines.append(body_text)\n",
    "        output_lines.append(\"</C>\")\n",
    "\n",
    "        # Replies\n",
    "        for i, reply in enumerate(comment.replies, 1):\n",
    "            new_id_prefix = f\"{id_prefix}.{i}\"\n",
    "            process_comment(reply, new_id_prefix, parent_id=comment_id)\n",
    "\n",
    "    for i, top_level_comment in enumerate(submission.comments, 1):\n",
    "        process_comment(top_level_comment, str(i), parent_id=\"P1\")\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "llm_transcript = linearize_tree_to_xml(submission)\n",
    "print(len(llm_transcript))\n",
    "print(llm_transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
